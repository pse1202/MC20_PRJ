# MC20_PRJ
멀티코어 컴퓨팅 프로젝트

## A. 계산 노드 1개의 CPU 사용

우선, 이미지의 갯수에 대한 loop에서 openmp를 이용해 병렬화를 했다.
그 뒤, convolution과 transposed convolution을 im2col 테크닉을 이용해서 matmul 형태로 변환하였다. 이 때, transposed convolution에 사용되는 filter는 차원이 행렬곱에 바로 사용할 수 없어 한번 변환해서 사용한다.
성능은 대략 2.15 img/sec 정도가 나왔다. (32개 기준)


## B. 계산 노드 1개의 CPU + GPU 1개 사용

우선 1개의 GPU가 한번에 미니배치(4개)의 이미지를 처리하도록 했다.
처음에 이미지를 변환해서 GPU에 올린 뒤, 모든 operator들에 대한 cuda kernel을 구현하여 각각 연속해서 실행하도록 하였다. 뼈대 코드에서와 마찬가지 이유로 처음에 GPU위에 포인터가 할당되면 그 크기가 일정하여 서로 다른 이미지마다 반복하여 사용할 수 있다. 그 결과, 대략 7.5 img/sec의 성능을 얻을 수 있었다. (128개 기준)
 
## C. 계산 노드 1개의 CPU + GPU 4개 사용

B와 마찬가지 방법으로 1개의 GPU 마다 미니배치의 이미지를 처리하도록 했다. 각 레이어 마다 모든 GPU에 커맨드를 실행시키는 방식을 사용했다. 마지막에 데이터를 모으는 과정을 제외하고는 blocking call을 하지 않았다.
그 결과, 26 img/sec의 성능을 얻을 수 있었다. (512개 기준)


## D. 계산 노드 4개의 CPU + GPU 16개 사용

C와 마찬가지 방법으로 작업하되, 이미지의 개수, 모델 파라미터, 이미지들을 우선 각 노드들에 분배한 뒤 마지막에 취합하는 방식으로 작업했다.
mpi와 cuda가 호환되지 않아 mpi를 사용하는 코드가 nvcc로 컴파일된 코드를 호출하도록 구성했다.
그 결과, 85img/sec의 성능을 얻을 수 있었다. (2048개 기준)
